zkFL stands for Zero Knowledge based Differentially Private Federated learning. It is a unique way to train DL models using decentralised computing & Zero-Knowledge proofs for enhanced security & faster computations based on trustlessness & ultra-privacy.

Federated Learning is a privacy-preserving scheme to train deep learning models. Data exists in isolated pools and clients that are part of the network train a model with base parameters on their data. They share the updated model parameters with an aggregator that takes the federated average of this set of models. The result is going to be a new updated base model for the next epoch of training.

To remove the dependency on the server, we leverage ZK-Proofs to make the server trustless. The Zk-Proofs are then shown publicly so that anyone can verify whether or not the computation was done correctly.

Ora zk oracles blog https://medium.com/@kenilshah1505/zk-oracles-b0960266d6e6

Mintclub erc20 tokens are incentivized to the user who verify the zk proofs 

![WhatsApp Image 2024-03-24 at 10 15 08](https://github.com/deepshah9696/FedLearning/assets/136230373/300933dc-f6b6-490d-a1a3-e29a3a770642)

Mint club contract deployed on sepolia
 https://sepolia.etherscan.io/token/0x5BDe71681b43B08de4580E7476829c7907Dd786C


Verifier Contract deployed on thundercore testnet 0xD1998CA0000f01442f54Ca8bF35017f43aa6ef26

Veirfier deployed on ten testnet  0xD1998CA0000f01442f54Ca8bF35017f43aa6ef26 

Verifier deployed on zircuit testnet 0xD1998CA0000f01442f54Ca8bF35017f43aa6ef26

Verifier deployed on scroll testnet 0xD1998CA0000f01442f54Ca8bF35017f43aa6ef26
